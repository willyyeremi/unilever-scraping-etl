name: unilever-scraping

x-airflow-common:
  &airflow-common
  build:
    context: .
    dockerfile: ./dockerfile/dockerfile.airflow
  image: unilever-scraping-airflow
  environment:
    AIRFLOW__API_AUTH__JWT_SECRET: ${API_JWT_SECRET}
    AIRFLOW__CORE__EXECUTOR: LocalExecutor
    AIRFLOW__CORE__EXECUTION_API_SERVER_URL: 'http://unilever-scraping-airflow-api-server:8080/execution/'
    AIRFLOW__CORE__FERNET_KEY:  ${FERNET_KEY}
    AIRFLOW__CORE__LOAD_EXAMPLES: 'False'
    AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://${AIRFLOW_DB_USERNAME}:${AIRFLOW_ODS_PASSWORD}@${AIRFLOW_ODS_HOST}:${AIRFLOW_ODS_PORT}/${AIRFLOW_ODS_DBNAME}
    AIRFLOW__LOGGING__WORKER_LOG_SERVER_HOST: airflow-scheduler
    AIRFLOW__WEBSERVER__SECRET_KEY: ${SECRET_KEY}
  volumes:
    - ./data/apache_airflow/logs:/opt/airflow/logs
    - ./data/apache_airflow/plugins:/opt/airflow/plugins
    - ./pipeline/apache_airflow:/opt/airflow/dags
  networks:
    - shared-network
  env_file:
    - .env

services:
  airflow-scheduler:
    <<: *airflow-common
    container_name: unilever-scraping-airflow-scheduler
    volumes:
      - ./data/apache_airflow/logs:/opt/airflow/logs
      - ./data/apache_airflow/plugins:/opt/airflow/plugins
      - ./pipeline/apache_airflow:/opt/airflow/dags
      - ./etc/apache_airflow:/home/airflow/initial_setup_tools
    command: >
      bash -c "
      airflow version &&     
      airflow db migrate && 
      python /home/airflow/initial_setup_tools/add_connection.py &&
      exec airflow scheduler
      "
  airflow-api-server:
    <<: *airflow-common
    container_name: unilever-scraping-airflow-api-server
    depends_on:
      - airflow-scheduler
    ports:
      - "8080:8080"
    volumes:
      - ./data/apache_airflow/logs:/opt/airflow/logs
      - ./data/apache_airflow/plugins:/opt/airflow/plugins
      - ./pipeline/apache_airflow:/opt/airflow/dags
      - ./etc/apache_airflow/webserver_config.py:/opt/airflow/webserver_config.py
    command: >
      bash -c "
      airflow version && 
      airflow db migrate && 
      airflow api-server --port 8080
      "
  airflow-dag-processor:
    <<: *airflow-common
    container_name: unilever-scraping-airflow-dag-processor
    depends_on:
      - airflow-scheduler
    command: >
      bash -c "
      airflow version && 
      airflow db migrate && 
      airflow dag-processor
      "
  airflow-triggerer:
    <<: *airflow-common
    container_name: unilever-scraping-airflow-triggerer
    depends_on:
      - airflow-scheduler
    command: >
      bash -c "
      airflow version && 
      airflow db migrate && 
      airflow triggerer
      "

networks:
  shared-network:
    name: unilever-scraping-network
    external: true
